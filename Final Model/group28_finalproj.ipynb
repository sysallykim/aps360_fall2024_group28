{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/MyDrive/')\n",
    "# Path to the zip file in Google Drive\n",
    "zip_path = '/content/drive/MyDrive/GTSRB.zip'\n",
    "\n",
    "# Extract the zip file to a specified directory\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/GTSRB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/content/GTSRB/Train'\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "classes = 43  # Number of traffic sign classes\n",
    "\n",
    "for i in range(classes):\n",
    "    path = os.path.join(data_dir, str(i))  \n",
    "    images = os.listdir(path)\n",
    "\n",
    "    for a in images:\n",
    "        try:\n",
    "            # Load and preprocess the image\n",
    "            image = Image.open(os.path.join(path, a))\n",
    "            image = image.resize((30, 30))  \n",
    "            image = np.array(image)\n",
    "            data.append(image)  \n",
    "            labels.append(i)  \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {a}: {e}\")\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Data shape: {data.shape}, Labels shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, labels.shape)\n",
    "\n",
    "# first split: train (70%) and test+validation (30%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# second split: validation (15%) and test (15%) from X_temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "class TrafficSignDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]  \n",
    "\n",
    "    \n",
    "        image = Image.fromarray(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(15),  # rotate by up to 15 degrees\n",
    "    transforms.RandomHorizontalFlip(),  # flip the image horizontally\n",
    "    transforms.RandomResizedCrop(30, scale=(0.8, 1.0)),  # random crop with resizing\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # random color jitter\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # random translation\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = TrafficSignDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = TrafficSignDataset(X_val, y_val, transform=transform)\n",
    "test_dataset = TrafficSignDataset(X_test, y_test, transform=transform_test)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "\n",
    "for images, labels in train_loader:\n",
    "    print(\"Batch images shape:\", images.shape)\n",
    "    print(\"Batch labels shape:\", labels.shape)\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrafficSignModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TrafficSignModel, self).__init__()\n",
    "\n",
    "        # conv Layer 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        # conv Layer 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        # max pooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # conv Layer 3\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # conv Layer 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        # max pooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        # FCL 1\n",
    "        self.fc1 = nn.Linear(256 * 7 * 7, 512)  # The flattened size depends on the input image size\n",
    "\n",
    "        # FCL 2\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "\n",
    "        # output Layer\n",
    "        self.fc3 = nn.Linear(256, 43)  # 43 classes\n",
    "\n",
    "        # dropout layers (used during training)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.dropout2 = nn.Dropout(0.20)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # flatten the tensor\n",
    "\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TrafficSignModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(43), yticklabels=range(43))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Average Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[str(i) for i in range(43)]))\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[str(i) for i in range(43)], yticklabels=[str(i) for i in range(43)])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on own images (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((30, 30)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class_labels = {\n",
    "    0: \"Speed Limit 20 km/h\",\n",
    "    1: \"Speed Limit 30 km/h\",\n",
    "    2: \"Speed Limit 50 km/h\",\n",
    "    3: \"Speed Limit 60 km/h\",\n",
    "    4: \"Speed Limit 70 km/h\",\n",
    "    5: \"Speed Limit 80 km/h\",\n",
    "    6: \"End of Speed Limit 80 km/h\",\n",
    "    7: \"Speed Limit 100 km/h\",\n",
    "    8: \"Speed Limit 120 km/h\",\n",
    "    9: \"No Overtaking\",\n",
    "    10: \"No Overtaking for Vehicles Over 3.5 Tons\",\n",
    "    11: \"Right-of-Way at Intersection\",\n",
    "    12: \"Main Road\",\n",
    "    13: \"Yield\",\n",
    "    14: \"Stop\",\n",
    "    15: \"No Vehicles\",\n",
    "    16: \"Vehicles Over 3.5 Tons Prohibited\",\n",
    "    17: \"No Entry\",\n",
    "    18: \"General Caution\",\n",
    "    19: \"Dangerous Curve to the Left\",\n",
    "    20: \"Dangerous Curve to the Right\",\n",
    "    21: \"Double Curve\",\n",
    "    22: \"Bumpy Road\",\n",
    "    23: \"Slippery Road\",\n",
    "    24: \"Road Narrows on the Right\",\n",
    "    25: \"Road Work\",\n",
    "    26: \"Traffic Signals\",\n",
    "    27: \"Pedestrians\",\n",
    "    28: \"Children Crossing\",\n",
    "    29: \"Bicycles Crossing\",\n",
    "    30: \"Beware of Ice/Snow\",\n",
    "    31: \"Wild Animals Crossing\",\n",
    "    32: \"End of All Restrictions\",\n",
    "    33: \"Turn Right Ahead\",\n",
    "    34: \"Turn Left Ahead\",\n",
    "    35: \"Ahead Only\",\n",
    "    36: \"Go Straight or Right\",\n",
    "    37: \"Go Straight or Left\",\n",
    "    38: \"Keep Right\",\n",
    "    39: \"Keep Left\",\n",
    "    40: \"Roundabout Mandatory\",\n",
    "    41: \"End of No Overtaking\",\n",
    "    42: \"End of No Overtaking for Vehicles Over 3.5 Tons\"\n",
    "}\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "def show_image(image_path):\n",
    "    original_image = Image.open(image_path).convert(\"RGB\")\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(original_image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.show()\n",
    "\n",
    "def classify_image(image_path):\n",
    "    original_image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    input_tensor = transform(original_image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "        predicted_class = probabilities.argmax()\n",
    "\n",
    "    print(f\"Predicted: {class_labels[predicted_class]} ({probabilities[predicted_class] * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/content/drive/My Drive/test photos/img3.png\"\n",
    "show_image(image_path)\n",
    "classify_image(image_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
